{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_map_db15k = {'birthDate':'birthDate',\n",
    " 'completionDate': 'completionDate',\n",
    " 'deathDate':'deathDate',\n",
    " 'formationDate':'formationDate',\n",
    " 'foundingDate': 'foundingDate',\n",
    " 'height': 'height',\n",
    " 'releaseDate': 'releaseDate',\n",
    " 'wgs84_pos#lat': 'latitude',\n",
    " 'wgs84_pos#long': 'longitude'}\n",
    "rel_map_mutag = {\n",
    "'http://dl-learner.org/mutagenesis#act' : 'mutagenesis\\#act',\n",
    " 'http://dl-learner.org/mutagenesis#charge': 'mutagenesis\\#charge',\n",
    " 'http://dl-learner.org/mutagenesis#logp' : 'mutagenesis\\#logp',\n",
    " 'http://dl-learner.org/mutagenesis#lumo' : 'mutagenesis\\#lumo'\n",
    "}\n",
    "rel_map_fb15k = {\n",
    "    'people.person.date_of_birth': 'date\\_of\\_birth',\n",
    "    'people.deceased_person.date_of_death': 'date\\_of\\_death',\n",
    "    'film.film.initial_release_date': 'release\\_date',\n",
    "    'organization.organization.date_founded': 'org.date\\_founded',\n",
    "    'location.dated_location.date_founded': 'loc.date\\_founded',\n",
    "    'location.geocode.latitude': 'latitude',\n",
    "    'location.geocode.longitude': 'longitude',\n",
    "    'location.location.area': 'loc.area',\n",
    "    'topic_server.population_number': 'pop.\\_number',\n",
    "    'people.person.height_meters': 'height\\_meters',\n",
    "    'people.person.weight_kg': 'weight\\_kg'\n",
    "}\n",
    "rel_map_yago15k = {\n",
    "    'diedOnDate': 'diedOnDate',\n",
    "    'happenedOnDate': 'happenedOnDate',\n",
    "    'hasLatitude': 'Latitude',\n",
    "    'hasLongitude': 'Longitude',\n",
    "    'wasBornOnDate': 'BornOnDate',\n",
    "    'wasCreatedOnDate': 'CreatedOnDate',\n",
    "    'wasDestroyedOnDate': 'DestroyedOnDate'\n",
    "}\n",
    "rel_map_yago15k_short = {\n",
    "    'diedOnDate': 'diedOnDate',\n",
    "    'happenedOnDate': 'happenedOnDate',\n",
    "    'hasLatitude': 'Latitude',\n",
    "    'hasLongitude': 'Longitude',\n",
    "    'wasBornOnDate': 'BornOnDate',\n",
    "    'wasCreatedOnDate': 'CreatedOn',\n",
    "    'wasDestroyedOnDate': 'DestroyedOn'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "relation & MAE_GLOBAL & MAE_LOCAL & LR_MAE & PLM_reg:MAE & MAE_litem \\\\\n",
      "\\midrule\n",
      "release\\_date & 12.200 & 9.849 & 5.590 & 5.526 & 4.258 \\\\\n",
      "loc.date\\_founded & 220.980 & 219.205 & 145.460 & 153.387 & 150.873 \\\\\n",
      "latitude & 12.403 & 2.997 & 8.470 & 8.741 & 5.221 \\\\\n",
      "longitude & 58.391 & 7.832 & 25.560 & 24.959 & 11.325 \\\\\n",
      "loc.area & 1842883.439 & 5101534.591 & 770000.000 & 1778305.891 & 1652001.300 \\\\\n",
      "org.date\\_founded & 81.029 & 81.482 & 53.850 & 71.632 & 46.741 \\\\\n",
      "date\\_of\\_death & 56.561 & 48.505 & 35.890 & 45.575 & 32.620 \\\\\n",
      "date\\_of\\_birth & 35.802 & 25.187 & 26.600 & 23.489 & 18.824 \\\\\n",
      "height\\_meters & 0.079 & 0.088 & 0.065 & 0.162 & 0.074 \\\\\n",
      "weight\\_kg & 12.506 & 16.367 & NaN & 9.515 & 12.653 \\\\\n",
      "pop.\\_number & 7184317.390 & 137764431.914 & 7900000.000 & 25998727.367 & 4873297.417 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Table 1 : Compare LitEm with GOBAL LOCAL LR KGE_Reg FB15k-237\n",
    "import pandas as pd\n",
    "dataset = \"FB15k-237\"\n",
    "local_global_df =  pd.read_csv(f\"Stats/{dataset}_LOCAL_GLOBAL.csv\", sep=',')\n",
    "approaches_df = pd.read_csv(f\"Stats/{dataset}_Reg.csv\", sep=',')\n",
    "litem_df = pd.read_csv(f\"Experiments/Literals/{dataset}/TransE_100/lit_results.csv\", sep=',')\n",
    "mae_cols = [col for col in litem_df.columns if \"MAE\" in col]\n",
    "rmse_cols = [col for col in litem_df.columns if \"RMSE\" in col]\n",
    "\n",
    "# Compute the mean across runs\n",
    "litem_df[\"MAE_litem\"] = litem_df[mae_cols].mean(axis=1)\n",
    "litem_df[\"RMSE_litem\"] = litem_df[rmse_cols].mean(axis=1)\n",
    "litem_dfs = litem_df[[\"relation\",\"MAE_litem\",\"RMSE_litem\"]]\n",
    "merged_df = pd.merge( local_global_df, approaches_df, on='relation', how='inner') \n",
    "final_df = pd.merge(merged_df, litem_dfs, on='relation', how='inner')\n",
    "pd.set_option('display.float_format', '{:.5f}'.format)\n",
    "filtered_df = final_df.loc[:, final_df.columns.str.contains('relation|MAE', case=False)]\n",
    "filtered_df.loc[:, \"relation\"] = filtered_df.loc[:, \"relation\"].map(rel_map_fb15k)\n",
    "latex_table = filtered_df.to_latex(index=False, float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "relation & MAE_GLOBAL & MAE_LOCAL & LR_MAE & MAE_PLM_reg & MAE_litem \\\\\n",
      "\\midrule\n",
      "diedOnDate & 58.508 & 55.072 & NaN & 50.119 & 40.515 \\\\\n",
      "happenedOnDate & 54.444 & 54.444 & NaN & 96.691 & 26.064 \\\\\n",
      "Latitude & 9.170 & 2.739 & NaN & 8.656 & 3.090 \\\\\n",
      "Longitude & 60.466 & 9.914 & NaN & 25.907 & 11.506 \\\\\n",
      "BornOnDate & 26.495 & 24.100 & NaN & 19.795 & 15.586 \\\\\n",
      "CreatedOnDate & 91.565 & 148.035 & NaN & 70.586 & 57.081 \\\\\n",
      "DestroyedOnDate & 42.639 & 43.554 & NaN & 41.972 & 21.436 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Table 1 : Compare LitEm with GOBAL LOCAL LR KGE_Reg-YAGO15k\n",
    "import pandas as pd\n",
    "\n",
    "dataset = \"YAGO15k\"\n",
    "local_global_df =  pd.read_csv(f\"Stats/{dataset}_LOCAL_GLOBAL.csv\", sep=',')\n",
    "approaches_df = pd.read_csv(f\"Stats/{dataset}_Reg.csv\", sep=',')\n",
    "litem_df = pd.read_csv(f\"Experiments/Literals/{dataset}/TransE_100/lit_results.csv\", sep=',')\n",
    "mae_cols = [col for col in litem_df.columns if \"MAE\" in col]\n",
    "rmse_cols = [col for col in litem_df.columns if \"RMSE\" in col]\n",
    "\n",
    "# Compute the mean across runs\n",
    "litem_df[\"MAE_litem\"] = litem_df[mae_cols].mean(axis=1)\n",
    "litem_df[\"RMSE_litem\"] = litem_df[rmse_cols].mean(axis=1)\n",
    "litem_dfs = litem_df[[\"relation\",\"MAE_litem\",\"RMSE_litem\"]]\n",
    "merged_df = pd.merge( local_global_df, approaches_df, on='relation', how='inner') \n",
    "final_df = pd.merge(merged_df, litem_dfs, on='relation', how='inner')\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "filtered_df = final_df.loc[:, final_df.columns.str.contains('relation|MAE', case=False)]\n",
    "filtered_df.loc[:, \"relation\"] = filtered_df.loc[:, \"relation\"].map(rel_map_yago15k)\n",
    "latex_table = filtered_df.to_latex(index=False, float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "relation & KGA_MAE & NAP++_MAE & MrAP_MAE & MAE_litem \\\\\n",
      "\\midrule\n",
      "date\\_of\\_birth & 18.900 & 22.100 & 15.000 & 18.824 \\\\\n",
      "date\\_of\\_death & 20.600 & 52.300 & 16.300 & 32.620 \\\\\n",
      "release\\_date & 4.000 & 9.900 & 6.300 & 4.258 \\\\\n",
      "org.date\\_founded & 49.000 & 59.300 & 58.300 & 46.741 \\\\\n",
      "loc.date\\_founded & 76.000 & 92.100 & 98.800 & 150.873 \\\\\n",
      "latitude & 2.100 & 11.800 & 1.500 & 5.221 \\\\\n",
      "longitude & 7.100 & 54.700 & 4.000 & 11.325 \\\\\n",
      "loc.area & 61000.000 & 440000.000 & 440000.000 & 1652001.300 \\\\\n",
      "pop.\\_number & 4000000.000 & 7500000.000 & 21000000.000 & 4873297.417 \\\\\n",
      "height\\_meters & 0.077 & 0.080 & 0.086 & 0.074 \\\\\n",
      "weight\\_kg & 11.600 & 15.300 & 12.900 & 12.653 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# table Appendix : Compare LitEm with KGA, NAP++, FB15k-237\n",
    "import pandas as pd\n",
    "dataset = \"FB15k-237\"\n",
    "sota_df =  pd.read_csv(f\"Stats/SOTA_LitPreds_{dataset}.csv\", sep=',')\n",
    "litem_df = pd.read_csv(f\"Experiments/Literals/{dataset}/TransE_100/lit_results.csv\", sep=',')\n",
    "mae_cols = [col for col in litem_df.columns if \"MAE\" in col]\n",
    "rmse_cols = [col for col in litem_df.columns if \"RMSE\" in col]\n",
    "# Compute the mean across runs\n",
    "litem_df[\"MAE_litem\"] = litem_df[mae_cols].mean(axis=1)\n",
    "litem_df[\"RMSE_litem\"] = litem_df[rmse_cols].mean(axis=1)\n",
    "litem_dfs = litem_df[[\"relation\",\"MAE_litem\",\"RMSE_litem\"]]\n",
    "final_df = pd.merge(sota_df, litem_dfs, on='relation', how='inner')\n",
    "pd.set_option('display.float_format', '{:.5f}'.format)\n",
    "filtered_df = final_df.loc[:, final_df.columns.str.contains('relation|MAE', case=False)]\n",
    "filtered_df.loc[:, \"relation\"] = filtered_df.loc[:, \"relation\"].map(rel_map_fb15k)\n",
    "latex_table = filtered_df.to_latex(index=False, float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "relation & KGA_MAE & NAP++_MAE & MrAP_MAE & MAE_litem \\\\\n",
      "\\midrule\n",
      "BornOnDate & 16.300 & 23.200 & 19.700 & 15.586 \\\\\n",
      "diedOnDate & 30.800 & 45.700 & 34.000 & 40.515 \\\\\n",
      "CreatedOnDate & 58.200 & 83.500 & 70.400 & 57.081 \\\\\n",
      "DestroyedOnDate & 23.300 & 38.200 & 34.600 & 21.436 \\\\\n",
      "happenedOnDate & 29.900 & 73.700 & 54.100 & 26.064 \\\\\n",
      "Latitude & 3.400 & 8.700 & 2.800 & 3.090 \\\\\n",
      "Longitude & 7.200 & 43.100 & 5.700 & 11.506 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# table Appendix : Compare LitEm with KGA, NAP++, YAGO\n",
    "import pandas as pd\n",
    "dataset = \"YAGO15k\"\n",
    "sota_df =  pd.read_csv(f\"Stats/SOTA_LitPreds_{dataset}.csv\", sep=',')\n",
    "litem_df = pd.read_csv(f\"Experiments/Literals/{dataset}/TransE_100/lit_results.csv\", sep=',')\n",
    "mae_cols = [col for col in litem_df.columns if \"MAE\" in col]\n",
    "rmse_cols = [col for col in litem_df.columns if \"RMSE\" in col]\n",
    "# Compute the mean across runs\n",
    "litem_df[\"MAE_litem\"] = litem_df[mae_cols].mean(axis=1)\n",
    "litem_df[\"RMSE_litem\"] = litem_df[rmse_cols].mean(axis=1)\n",
    "litem_dfs = litem_df[[\"relation\",\"MAE_litem\",\"RMSE_litem\"]]\n",
    "final_df = pd.merge(sota_df, litem_dfs, on='relation', how='inner')\n",
    "pd.set_option('display.float_format', '{:.5f}'.format)\n",
    "filtered_df = final_df.loc[:, final_df.columns.str.contains('relation|MAE', case=False)]\n",
    "filtered_df.loc[:, \"relation\"] = filtered_df.loc[:, \"relation\"].map(rel_map_yago15k)\n",
    "latex_table = filtered_df.to_latex(index=False, float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "relation & MAE_GLOBAL & RMSE_GLOBAL & MAE_LOCAL & RMSE_LOCAL & MAE_litem & RMSE_litem \\\\\n",
      "\\midrule\n",
      "birthDate & 23.361 & 34.421 & 21.695 & 31.137 & 12.408 & 19.697 \\\\\n",
      "completionDate & 9.425 & 11.298 & 7.692 & 9.485 & 4.735 & 5.880 \\\\\n",
      "deathDate & 26.636 & 38.643 & 25.987 & 36.824 & 17.624 & 32.317 \\\\\n",
      "formationDate & 40.358 & 47.105 & 40.358 & 47.105 & 46.091 & 53.207 \\\\\n",
      "foundingDate & 52.944 & 63.124 & 52.407 & 69.379 & 35.324 & 48.632 \\\\\n",
      "height & 1.403 & 1.408 & 1.403 & 1.408 & 2.060 & 2.505 \\\\\n",
      "releaseDate & 13.332 & 18.405 & 11.583 & 17.082 & 9.866 & 15.684 \\\\\n",
      "latitude & 11.830 & 17.656 & 7.081 & 15.124 & 4.811 & 9.161 \\\\\n",
      "longitude & 59.821 & 69.813 & 29.056 & 48.339 & 16.153 & 30.937 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Table 3: Part 1 DB15k GLOBAL LOCAL LitEM\n",
    "import pandas as pd\n",
    "dataset = \"DB15K\"\n",
    "local_global_df =  pd.read_csv(f\"Stats/{dataset}_LOCAL_GLOBAL.csv\", sep=',')\n",
    "# approaches_df = pd.read_csv(f\"Stats/{dataset}_Reg.csv\", sep=',')\n",
    "litem_df = pd.read_csv(f\"Experiments/Literals/{dataset}/TransE_100/lit_results.csv\", sep=',')\n",
    "mae_cols = [col for col in litem_df.columns if \"MAE\" in col]\n",
    "rmse_cols = [col for col in litem_df.columns if \"RMSE\" in col]\n",
    "\n",
    "# Compute the mean across runs\n",
    "litem_df[\"MAE_litem\"] = litem_df[mae_cols].mean(axis=1)\n",
    "litem_df[\"RMSE_litem\"] = litem_df[rmse_cols].mean(axis=1)\n",
    "litem_dfs = litem_df[[\"relation\",\"MAE_litem\",\"RMSE_litem\"]]\n",
    "# merged_df = pd.merge( local_global_df, approaches_df, on='relation', how='inner') \n",
    "final_df = pd.merge(local_global_df, litem_dfs, on='relation', how='inner')\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "filtered_df = final_df.loc[:, final_df.columns.str.contains('relation|MAE', case=False)]\n",
    "final_df.loc[:, \"relation\"] = final_df.loc[:, \"relation\"].map(rel_map_db15k)\n",
    "latex_table = final_df.to_latex(index=False, float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "relation & MAE_GLOBAL & RMSE_GLOBAL & MAE_LOCAL & RMSE_LOCAL & MAE_litem & RMSE_litem \\\\\n",
      "\\midrule\n",
      "mutagenesis\\#act & 1.932 & 2.301 & 1.932 & 2.301 & 1.467 & 1.827 \\\\\n",
      "mutagenesis\\#charge & 0.195 & 0.277 & 0.195 & 0.277 & 0.085 & 0.146 \\\\\n",
      "mutagenesis\\#logp & 1.218 & 1.569 & 1.218 & 1.569 & 0.739 & 0.965 \\\\\n",
      "mutagenesis\\#lumo & 0.361 & 0.451 & 0.361 & 0.451 & 0.302 & 0.366 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Table 3: Part 2: Mutag GLOBAL LOCAL LitEM\n",
    "import pandas as pd\n",
    "dataset = \"mutagenesis\"\n",
    "local_global_df =  pd.read_csv(f\"Stats/{dataset}_LOCAL_GLOBAL.csv\", sep=',')\n",
    "# approaches_df = pd.read_csv(f\"Stats/{dataset}_Reg.csv\", sep=',')\n",
    "litem_df = pd.read_csv(f\"Experiments/Literals/{dataset}/TransE_100/lit_results.csv\", sep=',')\n",
    "mae_cols = [col for col in litem_df.columns if \"MAE\" in col]\n",
    "rmse_cols = [col for col in litem_df.columns if \"RMSE\" in col]\n",
    "\n",
    "# Compute the mean across runs\n",
    "litem_df[\"MAE_litem\"] = litem_df[mae_cols].mean(axis=1)\n",
    "litem_df[\"RMSE_litem\"] = litem_df[rmse_cols].mean(axis=1)\n",
    "litem_dfs = litem_df[[\"relation\",\"MAE_litem\",\"RMSE_litem\"]]\n",
    "# merged_df = pd.merge( local_global_df, approaches_df, on='relation', how='inner') \n",
    "final_df = pd.merge(local_global_df, litem_dfs, on='relation', how='inner')\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "final_df.loc[:, \"relation\"] = final_df.loc[:, \"relation\"].map(rel_map_mutag)\n",
    "# # filtered_df = final_df.loc[:, final_df.columns.str.contains('relation|MAE', case=False)]\n",
    "latex_table = final_df.to_latex(index=False, float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "def get_kge_combined_table(dataset : str):  # Define column names\n",
    "    columns = [\"Model\", \"Dataset\", \"MRR\", \"H@1\", \"H@3\", \"H@10\", \n",
    "               \"MRR_Combined\", \"H@1_Combined\", \"H@3_Combined\", \"H@10_Combined\"]\n",
    "    \n",
    "    # Initialize an empty list to store data\n",
    "    data_rows = []\n",
    "    \n",
    "    exp_models = [\"ComplEx\", \"DeCaL\", \"DistMult\", \"Keci\", \"OMult\", \"QMult\", \"TransE\", \"Pykeen_MuRE\"]\n",
    "    \n",
    " \n",
    "    for model in exp_models:\n",
    "        # Define paths for original and combined evaluation reports\n",
    "        eval_file = f\"Experiments/KGE/{dataset}/{model}/eval_report.json\"\n",
    "        combined_dir = f\"Experiments/KGE_Combined/{dataset}_combined/{model}/eval_report.json\"\n",
    "        # Check if files exist before opening them\n",
    "        if not os.path.exists(eval_file) or not os.path.exists(combined_dir):\n",
    "            print(f\"Skipping {model} on {dataset} - Missing files\")\n",
    "            continue\n",
    "        \n",
    "        # Load original evaluation data\n",
    "        with open(eval_file, 'r') as file:\n",
    "            eval_data = json.load(file)\n",
    "    \n",
    "        # Load combined evaluation data\n",
    "        with open(combined_dir, 'r') as file:\n",
    "            eval_data_combined = json.load(file)\n",
    "    \n",
    "        # Function to extract metrics\n",
    "        def extract_metrics(data, split_name):\n",
    "            metrics = data.get(split_name, {})\n",
    "            return [\n",
    "                metrics.get(\"MRR\", \"\"), metrics.get(\"H@1\", \"\"), \n",
    "                metrics.get(\"H@3\", \"\"), metrics.get(\"H@10\", \"\")\n",
    "            ]\n",
    "    \n",
    "        # Iteratively add rows for Train, Test, and Val datasets\n",
    "        for split in [\"Train\", \"Test\", \"Val\"]:  # Renamed loop variable to avoid conflict\n",
    "            row = [model, dataset] + extract_metrics(eval_data, split) + extract_metrics(eval_data_combined, split)\n",
    "            data_rows.append(row)  # Append instead of overwriting\n",
    "    \n",
    "    # Create DataFrame from collected rows\n",
    "    df = pd.DataFrame(data_rows, columns=columns)\n",
    "    sub_df = df.drop(columns=['Dataset'])\n",
    "    return sub_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "Model & MRR & H@1 & H@3 & H@10 & MRR_Combined & H@1_Combined & H@3_Combined & H@10_Combined \\\\\n",
      "\\midrule\n",
      "ComplEx & 0.632 & 0.543 & 0.680 & 0.797 & 0.865 & 0.818 & 0.898 & 0.951 \\\\\n",
      "ComplEx & 0.194 & 0.127 & 0.212 & 0.328 & 0.303 & 0.227 & 0.336 & 0.453 \\\\\n",
      "ComplEx & 0.197 & 0.129 & 0.217 & 0.329 & 0.302 & 0.226 & 0.334 & 0.450 \\\\\n",
      "DeCaL & 0.817 & 0.756 & 0.860 & 0.928 & 0.828 & 0.765 & 0.872 & 0.932 \\\\\n",
      "DeCaL & 0.278 & 0.202 & 0.307 & 0.424 & 0.297 & 0.218 & 0.329 & 0.452 \\\\\n",
      "DeCaL & 0.279 & 0.203 & 0.307 & 0.432 & 0.297 & 0.219 & 0.331 & 0.447 \\\\\n",
      "DistMult & 0.873 & 0.828 & 0.904 & 0.952 & 0.851 & 0.801 & 0.885 & 0.940 \\\\\n",
      "DistMult & 0.282 & 0.208 & 0.310 & 0.430 & 0.306 & 0.233 & 0.338 & 0.444 \\\\\n",
      "DistMult & 0.287 & 0.213 & 0.316 & 0.434 & 0.308 & 0.237 & 0.337 & 0.446 \\\\\n",
      "Keci & 0.849 & 0.793 & 0.890 & 0.943 & 0.877 & 0.832 & 0.911 & 0.960 \\\\\n",
      "Keci & 0.306 & 0.234 & 0.335 & 0.447 & 0.327 & 0.252 & 0.360 & 0.473 \\\\\n",
      "Keci & 0.311 & 0.241 & 0.338 & 0.449 & 0.328 & 0.253 & 0.362 & 0.470 \\\\\n",
      "OMult & 0.813 & 0.753 & 0.851 & 0.921 & 0.827 & 0.771 & 0.863 & 0.927 \\\\\n",
      "OMult & 0.250 & 0.175 & 0.280 & 0.393 & 0.266 & 0.198 & 0.290 & 0.400 \\\\\n",
      "OMult & 0.255 & 0.181 & 0.286 & 0.395 & 0.269 & 0.199 & 0.294 & 0.404 \\\\\n",
      "QMult & 0.806 & 0.742 & 0.849 & 0.918 & 0.859 & 0.815 & 0.888 & 0.938 \\\\\n",
      "QMult & 0.250 & 0.180 & 0.275 & 0.386 & 0.273 & 0.202 & 0.300 & 0.408 \\\\\n",
      "QMult & 0.254 & 0.181 & 0.282 & 0.396 & 0.273 & 0.201 & 0.300 & 0.411 \\\\\n",
      "TransE & 0.588 & 0.503 & 0.635 & 0.744 & 0.556 & 0.471 & 0.601 & 0.718 \\\\\n",
      "TransE & 0.220 & 0.143 & 0.239 & 0.374 & 0.214 & 0.137 & 0.235 & 0.365 \\\\\n",
      "TransE & 0.226 & 0.147 & 0.250 & 0.379 & 0.220 & 0.142 & 0.241 & 0.371 \\\\\n",
      "Pykeen_MuRE & 0.850 & 0.800 & 0.886 & 0.937 & 0.827 & 0.774 & 0.863 & 0.919 \\\\\n",
      "Pykeen_MuRE & 0.315 & 0.239 & 0.345 & 0.462 & 0.314 & 0.237 & 0.345 & 0.463 \\\\\n",
      "Pykeen_MuRE & 0.319 & 0.242 & 0.351 & 0.465 & 0.318 & 0.239 & 0.349 & 0.470 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp_dataset = get_kge_combined_table(dataset = \"YAGO15k\")\n",
    "latex_table = lp_dataset.to_latex(index=False, float_format=\"%.3f\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "Model & MRR & H@1 & H@3 & H@10 & MRR_Combined & H@1_Combined & H@3_Combined & H@10_Combined \\\\\n",
      "\\midrule\n",
      "ComplEx & 0.713 & 0.631 & 0.766 & 0.864 & 0.724 & 0.645 & 0.771 & 0.877 \\\\\n",
      "ComplEx & 0.256 & 0.198 & 0.277 & 0.366 & 0.262 & 0.205 & 0.283 & 0.377 \\\\\n",
      "ComplEx & 0.265 & 0.208 & 0.287 & 0.376 & 0.269 & 0.210 & 0.290 & 0.383 \\\\\n",
      "DeCaL & 0.727 & 0.654 & 0.769 & 0.883 & 0.719 & 0.637 & 0.762 & 0.881 \\\\\n",
      "DeCaL & 0.285 & 0.227 & 0.310 & 0.399 & 0.291 & 0.227 & 0.316 & 0.417 \\\\\n",
      "DeCaL & 0.283 & 0.224 & 0.306 & 0.397 & 0.290 & 0.223 & 0.316 & 0.420 \\\\\n",
      "DistMult & 0.718 & 0.630 & 0.781 & 0.864 & 0.737 & 0.648 & 0.805 & 0.883 \\\\\n",
      "DistMult & 0.242 & 0.184 & 0.265 & 0.349 & 0.265 & 0.201 & 0.291 & 0.391 \\\\\n",
      "DistMult & 0.247 & 0.188 & 0.270 & 0.360 & 0.268 & 0.202 & 0.295 & 0.394 \\\\\n",
      "Keci & 0.774 & 0.694 & 0.831 & 0.909 & 0.763 & 0.678 & 0.824 & 0.901 \\\\\n",
      "Keci & 0.290 & 0.226 & 0.317 & 0.409 & 0.301 & 0.235 & 0.329 & 0.427 \\\\\n",
      "Keci & 0.292 & 0.228 & 0.319 & 0.416 & 0.304 & 0.238 & 0.331 & 0.431 \\\\\n",
      "OMult & 0.775 & 0.716 & 0.811 & 0.882 & 0.783 & 0.721 & 0.822 & 0.894 \\\\\n",
      "OMult & 0.247 & 0.197 & 0.265 & 0.340 & 0.244 & 0.194 & 0.259 & 0.343 \\\\\n",
      "OMult & 0.249 & 0.198 & 0.268 & 0.347 & 0.244 & 0.190 & 0.260 & 0.349 \\\\\n",
      "QMult & 0.799 & 0.735 & 0.841 & 0.912 & 0.798 & 0.737 & 0.833 & 0.909 \\\\\n",
      "QMult & 0.249 & 0.198 & 0.266 & 0.348 & 0.256 & 0.199 & 0.277 & 0.366 \\\\\n",
      "QMult & 0.254 & 0.202 & 0.273 & 0.356 & 0.261 & 0.203 & 0.282 & 0.373 \\\\\n",
      "TransE & 0.599 & 0.500 & 0.667 & 0.774 & 0.569 & 0.466 & 0.637 & 0.751 \\\\\n",
      "TransE & 0.328 & 0.233 & 0.374 & 0.509 & 0.316 & 0.220 & 0.363 & 0.500 \\\\\n",
      "TransE & 0.333 & 0.238 & 0.383 & 0.515 & 0.318 & 0.220 & 0.368 & 0.506 \\\\\n",
      "Pykeen_MuRE & 0.784 & 0.726 & 0.821 & 0.890 & 0.759 & 0.699 & 0.792 & 0.879 \\\\\n",
      "Pykeen_MuRE & 0.311 & 0.250 & 0.336 & 0.426 & 0.307 & 0.245 & 0.334 & 0.427 \\\\\n",
      "Pykeen_MuRE & 0.312 & 0.250 & 0.337 & 0.430 & 0.307 & 0.243 & 0.334 & 0.432 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp_dataset = get_kge_combined_table(dataset = \"DB15K\")\n",
    "latex_table = lp_dataset.to_latex(index=False, float_format=\"%.3f\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "Model & MRR & H@1 & H@3 & H@10 & MRR_Combined & H@1_Combined & H@3_Combined & H@10_Combined \\\\\n",
      "\\midrule\n",
      "ComplEx & 0.458 & 0.352 & 0.512 & 0.662 & 0.415 & 0.312 & 0.465 & 0.616 \\\\\n",
      "ComplEx & 0.247 & 0.174 & 0.270 & 0.393 & 0.234 & 0.165 & 0.253 & 0.372 \\\\\n",
      "ComplEx & 0.247 & 0.174 & 0.269 & 0.393 & 0.237 & 0.168 & 0.256 & 0.372 \\\\\n",
      "DeCaL & 0.513 & 0.413 & 0.565 & 0.706 & 0.496 & 0.393 & 0.549 & 0.695 \\\\\n",
      "DeCaL & 0.262 & 0.186 & 0.286 & 0.415 & 0.260 & 0.183 & 0.283 & 0.413 \\\\\n",
      "DeCaL & 0.264 & 0.187 & 0.288 & 0.418 & 0.260 & 0.184 & 0.284 & 0.413 \\\\\n",
      "DistMult & 0.475 & 0.372 & 0.529 & 0.676 & 0.454 & 0.347 & 0.509 & 0.660 \\\\\n",
      "DistMult & 0.245 & 0.170 & 0.268 & 0.396 & 0.243 & 0.170 & 0.266 & 0.389 \\\\\n",
      "DistMult & 0.247 & 0.173 & 0.270 & 0.394 & 0.243 & 0.170 & 0.265 & 0.388 \\\\\n",
      "Keci & 0.543 & 0.438 & 0.602 & 0.744 & 0.519 & 0.415 & 0.576 & 0.718 \\\\\n",
      "Keci & 0.260 & 0.182 & 0.284 & 0.417 & 0.268 & 0.190 & 0.290 & 0.426 \\\\\n",
      "Keci & 0.264 & 0.186 & 0.289 & 0.420 & 0.270 & 0.191 & 0.296 & 0.427 \\\\\n",
      "OMult & 0.530 & 0.431 & 0.584 & 0.721 & 0.468 & 0.366 & 0.518 & 0.665 \\\\\n",
      "OMult & 0.230 & 0.156 & 0.253 & 0.376 & 0.230 & 0.158 & 0.251 & 0.371 \\\\\n",
      "OMult & 0.233 & 0.160 & 0.255 & 0.378 & 0.231 & 0.159 & 0.252 & 0.374 \\\\\n",
      "QMult & 0.544 & 0.443 & 0.598 & 0.736 & 0.535 & 0.434 & 0.589 & 0.728 \\\\\n",
      "QMult & 0.255 & 0.179 & 0.276 & 0.410 & 0.260 & 0.182 & 0.282 & 0.416 \\\\\n",
      "QMult & 0.261 & 0.184 & 0.283 & 0.413 & 0.262 & 0.185 & 0.283 & 0.417 \\\\\n",
      "TransE & 0.429 & 0.306 & 0.499 & 0.660 & 0.409 & 0.287 & 0.476 & 0.638 \\\\\n",
      "TransE & 0.307 & 0.217 & 0.341 & 0.481 & 0.301 & 0.213 & 0.335 & 0.473 \\\\\n",
      "TransE & 0.311 & 0.222 & 0.345 & 0.484 & 0.306 & 0.219 & 0.341 & 0.480 \\\\\n",
      "Pykeen_MuRE & 0.493 & 0.388 & 0.549 & 0.693 & 0.485 & 0.381 & 0.539 & 0.686 \\\\\n",
      "Pykeen_MuRE & 0.267 & 0.191 & 0.289 & 0.420 & 0.270 & 0.194 & 0.292 & 0.424 \\\\\n",
      "Pykeen_MuRE & 0.272 & 0.195 & 0.295 & 0.426 & 0.274 & 0.198 & 0.294 & 0.429 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp_dataset = get_kge_combined_table(dataset = \"FB15k-237\")\n",
    "latex_table = lp_dataset.to_latex(index=False, float_format=\"%.3f\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "Model & MRR & H@1 & H@3 & H@10 & MRR_Combined & H@1_Combined & H@3_Combined & H@10_Combined \\\\\n",
      "\\midrule\n",
      "ComplEx & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 \\\\\n",
      "ComplEx & 0.226 & 0.158 & 0.249 & 0.357 & 0.174 & 0.109 & 0.187 & 0.315 \\\\\n",
      "ComplEx & 0.218 & 0.149 & 0.240 & 0.345 & 0.172 & 0.107 & 0.186 & 0.314 \\\\\n",
      "DeCaL & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 \\\\\n",
      "DeCaL & 0.130 & 0.077 & 0.131 & 0.241 & 0.154 & 0.093 & 0.160 & 0.280 \\\\\n",
      "DeCaL & 0.128 & 0.073 & 0.134 & 0.244 & 0.152 & 0.089 & 0.160 & 0.280 \\\\\n",
      "DistMult & 1.000 & 1.000 & 1.000 & 1.000 & 0.997 & 0.995 & 1.000 & 1.000 \\\\\n",
      "DistMult & 0.177 & 0.095 & 0.206 & 0.322 & 0.239 & 0.161 & 0.269 & 0.372 \\\\\n",
      "DistMult & 0.181 & 0.098 & 0.210 & 0.324 & 0.243 & 0.165 & 0.272 & 0.377 \\\\\n",
      "Keci & 1.000 & 1.000 & 1.000 & 1.000 & 0.933 & 0.875 & 1.000 & 1.000 \\\\\n",
      "Keci & 0.103 & 0.059 & 0.105 & 0.174 & 0.158 & 0.109 & 0.162 & 0.246 \\\\\n",
      "Keci & 0.095 & 0.054 & 0.094 & 0.166 & 0.159 & 0.109 & 0.162 & 0.252 \\\\\n",
      "OMult & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 \\\\\n",
      "OMult & 0.070 & 0.030 & 0.061 & 0.149 & 0.202 & 0.102 & 0.283 & 0.389 \\\\\n",
      "OMult & 0.071 & 0.031 & 0.065 & 0.145 & 0.199 & 0.102 & 0.278 & 0.379 \\\\\n",
      "QMult & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 \\\\\n",
      "QMult & 0.224 & 0.147 & 0.256 & 0.359 & 0.263 & 0.189 & 0.289 & 0.389 \\\\\n",
      "QMult & 0.217 & 0.138 & 0.252 & 0.351 & 0.254 & 0.183 & 0.279 & 0.379 \\\\\n",
      "TransE & 0.779 & 0.721 & 0.817 & 0.882 & 0.769 & 0.710 & 0.806 & 0.877 \\\\\n",
      "TransE & 0.563 & 0.473 & 0.620 & 0.713 & 0.568 & 0.483 & 0.624 & 0.704 \\\\\n",
      "TransE & 0.548 & 0.459 & 0.599 & 0.696 & 0.555 & 0.475 & 0.602 & 0.687 \\\\\n",
      "Pykeen_MuRE & 1.000 & 0.999 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 \\\\\n",
      "Pykeen_MuRE & 0.541 & 0.461 & 0.554 & 0.758 & 0.532 & 0.470 & 0.547 & 0.626 \\\\\n",
      "Pykeen_MuRE & 0.518 & 0.435 & 0.533 & 0.742 & 0.511 & 0.450 & 0.526 & 0.602 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp_dataset = get_kge_combined_table(dataset = \"mutagenesis\")\n",
    "latex_table = lp_dataset.to_latex(index=False, float_format=\"%.3f\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "relation & ComplEx & DeCaL & DistMult & Keci & MuRE & OMult & QMult & TransE \\\\\n",
      "\\midrule\n",
      "release\\_date & 5.317 & 5.333 & 5.070 & 5.022 & 5.062 & 5.461 & 5.140 & 4.813 \\\\\n",
      "loc.date\\_founded & 185.434 & 183.784 & 182.430 & 174.937 & 178.819 & 182.161 & 183.216 & 169.235 \\\\\n",
      "latitude & 9.276 & 9.351 & 8.379 & 8.959 & 7.573 & 8.763 & 9.578 & 6.420 \\\\\n",
      "longitude & 22.550 & 22.843 & 20.609 & 21.226 & 20.439 & 24.194 & 23.402 & 15.935 \\\\\n",
      "loc.area & 1667051.989 & 1686339.028 & 1666283.796 & 1680406.021 & 1644623.816 & 1704068.346 & 1665585.301 & 1638994.603 \\\\\n",
      "org.date\\_founded & 58.269 & 61.449 & 63.043 & 64.214 & 61.223 & 60.434 & 63.648 & 56.818 \\\\\n",
      "date\\_of\\_death & 40.127 & 40.118 & 44.889 & 41.223 & 38.519 & 37.994 & 39.873 & 35.760 \\\\\n",
      "date\\_of\\_birth & 22.860 & 23.716 & 24.065 & 22.837 & 21.428 & 22.923 & 22.906 & 20.675 \\\\\n",
      "height\\_meters & 0.066 & 0.067 & 0.066 & 0.067 & 0.066 & 0.068 & 0.069 & 0.074 \\\\\n",
      "weight\\_kg & 12.246 & 11.389 & 12.980 & 11.290 & 12.932 & 11.713 & 10.650 & 12.659 \\\\\n",
      "pop.\\_number & 5088897.793 & 5440441.705 & 4792079.011 & 5026720.806 & 4464004.186 & 5568670.390 & 4789106.391 & 4386149.948 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dataset = \"FB15k-237\"\n",
    "exp_models = [\"ComplEx\", \"DeCaL\", \"DistMult\", \"Keci\", \"OMult\", \"QMult\", \"TransE\", \"MuRE\"]\n",
    "column_order = [\"relation\", \"ComplEx\", \"DeCaL\", \"DistMult\", \"Keci\",\"MuRE\", \"OMult\", \"QMult\", \"TransE\"]\n",
    "exp_dir = f\"Experiments/Literals/{dataset}\"\n",
    "dim = 32\n",
    "df_average = pd.DataFrame() \n",
    "for model in exp_models:\n",
    "    sub_path = os.path.join(exp_dir, model)\n",
    "    sub_path = f\"{sub_path}_{dim}\"\n",
    "    lit_results_path = os.path.join(sub_path,\"lit_results.csv\" )\n",
    "    try:\n",
    "        lit_results = pd.read_csv(lit_results_path)\n",
    "        # Identify MAE and RMSE columns\n",
    "        mae_cols = [col for col in lit_results.columns if \"MAE\" in col]\n",
    "        # rmse_cols = [col for col in lit_results.columns if \"RMSE\" in col]\n",
    "\n",
    "        # Compute the mean across runs\n",
    "        lit_results[\"MAE\"] = lit_results[mae_cols].mean(axis=1)\n",
    "        # lit_results[\"RMSE\"] = lit_results[rmse_cols].mean(axis=1)\n",
    "\n",
    "        # Set relation as index\n",
    "        lit_results = lit_results.set_index(\"relation\")\n",
    "\n",
    "        lit_results = lit_results[[\"MAE\"]].rename(\n",
    "                columns={\"MAE\": f\"{model}\"}\n",
    "            )\n",
    "        # Merge with the main DataFrame\n",
    "        if df_average.empty:\n",
    "            df_average = lit_results\n",
    "        else:\n",
    "            df_average = df_average.join(lit_results, how=\"outer\")\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "df_average = df_average.apply(pd.to_numeric).round(3)\n",
    "\n",
    "df_average = df_average[sorted(df_average.columns)]\n",
    "df_average = df_average.reset_index()\n",
    "df_average.loc[:, \"relation\"] = df_average.loc[:, \"relation\"].map(rel_map_fb15k)\n",
    "df_average = df_average[column_order]\n",
    "latex_table = df_average.to_latex(index=False, float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "relation & ComplEx & DeCaL & DistMult & Keci & MuRE & OMult & QMult & TransE \\\\\n",
      "\\midrule\n",
      "birthDate & 18.318 & 18.598 & 18.306 & 17.619 & 15.973 & 18.943 & 17.691 & 14.403 \\\\\n",
      "completionDate & 8.275 & 8.377 & 8.180 & 7.259 & 8.016 & 8.059 & 8.426 & 5.854 \\\\\n",
      "deathDate & 20.115 & 21.330 & 21.550 & 20.036 & 20.876 & 21.349 & 18.595 & 19.432 \\\\\n",
      "formationDate & 43.400 & 37.897 & 39.715 & 43.236 & 39.298 & 37.228 & 38.110 & 39.945 \\\\\n",
      "foundingDate & 39.780 & 40.739 & 42.937 & 43.307 & 43.092 & 44.545 & 40.878 & 37.933 \\\\\n",
      "height & 1.798 & 1.869 & 2.280 & 2.163 & 1.663 & 2.528 & 2.271 & 2.189 \\\\\n",
      "releaseDate & 11.319 & 12.818 & 12.839 & 12.035 & 11.728 & 12.982 & 12.721 & 9.218 \\\\\n",
      "latitude & 8.077 & 8.928 & 8.720 & 8.201 & 8.105 & 9.474 & 9.105 & 5.944 \\\\\n",
      "longitude & 30.947 & 29.970 & 30.662 & 32.365 & 27.653 & 34.371 & 31.704 & 21.737 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dataset = \"DB15K\"\n",
    "exp_models = [\"ComplEx\", \"DeCaL\", \"DistMult\", \"Keci\", \"OMult\", \"QMult\", \"TransE\", \"MuRE\"]\n",
    "column_order = [\"relation\", \"ComplEx\", \"DeCaL\", \"DistMult\", \"Keci\",\"MuRE\", \"OMult\", \"QMult\", \"TransE\"]\n",
    "exp_dir = f\"Experiments/Literals/{dataset}\"\n",
    "dim = 32\n",
    "df_average = pd.DataFrame() \n",
    "for model in exp_models:\n",
    "    sub_path = os.path.join(exp_dir, model)\n",
    "    sub_path = f\"{sub_path}_{dim}\"\n",
    "    lit_results_path = os.path.join(sub_path,\"lit_results.csv\" )\n",
    "    try:\n",
    "        lit_results = pd.read_csv(lit_results_path)\n",
    "        # Identify MAE and RMSE columns\n",
    "        mae_cols = [col for col in lit_results.columns if \"MAE\" in col]\n",
    "        # rmse_cols = [col for col in lit_results.columns if \"RMSE\" in col]\n",
    "\n",
    "        # Compute the mean across runs\n",
    "        lit_results[\"MAE\"] = lit_results[mae_cols].mean(axis=1)\n",
    "        # lit_results[\"RMSE\"] = lit_results[rmse_cols].mean(axis=1)\n",
    "\n",
    "        # Set relation as index\n",
    "        lit_results = lit_results.set_index(\"relation\")\n",
    "\n",
    "        lit_results = lit_results[[\"MAE\"]].rename(\n",
    "                columns={\"MAE\": f\"{model}\"}\n",
    "            )\n",
    "        # Merge with the main DataFrame\n",
    "        if df_average.empty:\n",
    "            df_average = lit_results\n",
    "        else:\n",
    "            df_average = df_average.join(lit_results, how=\"outer\")\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "df_average = df_average.apply(pd.to_numeric).round(3)\n",
    "\n",
    "df_average = df_average[sorted(df_average.columns)]\n",
    "df_average = df_average.reset_index()\n",
    "df_average.loc[:, \"relation\"] = df_average.loc[:, \"relation\"].map(rel_map_db15k)\n",
    "df_average = df_average[column_order]\n",
    "latex_table = df_average.to_latex(index=False, float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "relation & ComplEx & DeCaL & DistMult & Keci & MuRE & OMult & QMult & TransE \\\\\n",
      "\\midrule\n",
      "diedOnDate & 48.445 & 47.529 & 48.797 & 46.645 & 46.045 & 47.261 & 48.379 & 44.932 \\\\\n",
      "happenedOnDate & 41.277 & 42.306 & 42.882 & 44.801 & 36.921 & 39.471 & 39.587 & 29.847 \\\\\n",
      "Latitude & 7.416 & 7.216 & 6.972 & 6.939 & 6.189 & 7.245 & 6.815 & 4.652 \\\\\n",
      "Longitude & 30.081 & 27.004 & 30.644 & 31.004 & 26.406 & 36.895 & 32.239 & 17.490 \\\\\n",
      "BornOnDate & 20.690 & 19.798 & 20.525 & 20.776 & 18.999 & 20.061 & 20.516 & 17.458 \\\\\n",
      "CreatedOnDate & 67.496 & 67.581 & 67.695 & 70.348 & 62.844 & 68.904 & 68.421 & 62.785 \\\\\n",
      "DestroyedOnDate & 27.670 & 28.214 & 29.231 & 27.093 & 27.899 & 27.564 & 27.649 & 23.658 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dataset = \"YAGO15k\"\n",
    "exp_models = [\"ComplEx\", \"DeCaL\", \"DistMult\", \"Keci\", \"OMult\", \"QMult\", \"TransE\", \"MuRE\"]\n",
    "column_order = [\"relation\", \"ComplEx\", \"DeCaL\", \"DistMult\", \"Keci\",\"MuRE\", \"OMult\", \"QMult\", \"TransE\"]\n",
    "exp_dir = f\"Experiments/Literals/{dataset}\"\n",
    "dim = 32\n",
    "df_average = pd.DataFrame() \n",
    "for model in exp_models:\n",
    "    sub_path = os.path.join(exp_dir, model)\n",
    "    sub_path = f\"{sub_path}_{dim}\"\n",
    "    lit_results_path = os.path.join(sub_path,\"lit_results.csv\" )\n",
    "    try:\n",
    "        lit_results = pd.read_csv(lit_results_path)\n",
    "        # Identify MAE and RMSE columns\n",
    "        mae_cols = [col for col in lit_results.columns if \"MAE\" in col]\n",
    "        # rmse_cols = [col for col in lit_results.columns if \"RMSE\" in col]\n",
    "\n",
    "        # Compute the mean across runs\n",
    "        lit_results[\"MAE\"] = lit_results[mae_cols].mean(axis=1)\n",
    "        # lit_results[\"RMSE\"] = lit_results[rmse_cols].mean(axis=1)\n",
    "\n",
    "        # Set relation as index\n",
    "        lit_results = lit_results.set_index(\"relation\")\n",
    "\n",
    "        lit_results = lit_results[[\"MAE\"]].rename(\n",
    "                columns={\"MAE\": f\"{model}\"}\n",
    "            )\n",
    "        # Merge with the main DataFrame\n",
    "        if df_average.empty:\n",
    "            df_average = lit_results\n",
    "        else:\n",
    "            df_average = df_average.join(lit_results, how=\"outer\")\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "df_average = df_average.apply(pd.to_numeric).round(3)\n",
    "\n",
    "df_average = df_average[sorted(df_average.columns)]\n",
    "df_average = df_average.reset_index()\n",
    "df_average.loc[:, \"relation\"] = df_average.loc[:, \"relation\"].map(rel_map_yago15k)\n",
    "df_average = df_average[column_order]\n",
    "latex_table = df_average.to_latex(index=False, float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "relation & ComplEx & DeCaL & DistMult & Keci & Pykeen_MuRE & OMult & QMult & TransE \\\\\n",
      "\\midrule\n",
      "release\\_date & 6.999 & 9.926 & 8.939 & 6.838 & 11.596 & 6.228 & 5.773 & 7.803 \\\\\n",
      "loc.date\\_founded & 215.292 & 211.453 & 289.618 & 257.083 & 182.757 & 177.827 & 209.617 & 235.362 \\\\\n",
      "latitude & 9.546 & 15.456 & 10.314 & 9.961 & 6.979 & 10.150 & 9.119 & 9.284 \\\\\n",
      "longitude & 22.085 & 49.033 & 29.283 & 34.827 & 24.229 & 25.056 & 26.121 & 22.184 \\\\\n",
      "loc.area & 1833278.464 & 2287340.082 & 2021117.976 & 2014092.989 & 1769531.672 & 1955924.387 & 1908406.363 & 1914633.817 \\\\\n",
      "org.date\\_founded & 77.473 & 88.050 & 81.105 & 75.548 & 61.761 & 67.695 & 79.752 & 53.938 \\\\\n",
      "date\\_of\\_death & 30.047 & 58.544 & 41.277 & 44.620 & 22.757 & 26.084 & 38.558 & 35.922 \\\\\n",
      "date\\_of\\_birth & 19.917 & 38.284 & 23.505 & 38.946 & 16.636 & 17.750 & 26.118 & 16.119 \\\\\n",
      "height\\_meters & 0.082 & 0.077 & 0.083 & 0.069 & 0.080 & 0.075 & 0.078 & 0.078 \\\\\n",
      "weight\\_kg & 11.013 & 9.404 & 10.540 & 10.046 & 10.316 & 9.477 & 11.777 & 8.954 \\\\\n",
      "pop.\\_number & 8592847.655 & 11915682.728 & 8069453.786 & 14240395.394 & 7910109.094 & 10643859.445 & 8137684.281 & 9339775.342 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dataset = \"FB15k-237\"\n",
    "exp_dir = f\"Experiments/KGE_Combined/{dataset}_combined/\"\n",
    "column_order = [\"relation\", \"ComplEx\", \"DeCaL\", \"DistMult\", \"Keci\",\"Pykeen_MuRE\", \"OMult\", \"QMult\", \"TransE\"]\n",
    "df_average = pd.DataFrame() \n",
    "for sub_dir in os.listdir(exp_dir):\n",
    "    sub_path = os.path.join(exp_dir, sub_dir)\n",
    "    lit_results_path = os.path.join(sub_path,\"lit_results.json\" )\n",
    "    lit_results = pd.read_json(lit_results_path)\n",
    "    # Identify MAE and RMSE columns\n",
    "    mae_cols = [col for col in lit_results.columns if \"MAE\" in col]\n",
    "    # rmse_cols = [col for col in lit_results.columns if \"RMSE\" in col]\n",
    "\n",
    "    # Compute the mean across runs\n",
    "    lit_results[\"MAE\"] = lit_results[mae_cols].mean(axis=1)\n",
    "    # lit_results[\"RMSE\"] = lit_results[rmse_cols].mean(axis=1)\n",
    "\n",
    "    # Set relation as index\n",
    "    lit_results = lit_results.set_index(\"relation\")\n",
    "\n",
    "    lit_results = lit_results[[\"MAE\"]].rename(\n",
    "            columns={\"MAE\": f\"{sub_dir}\"}\n",
    "        )\n",
    "    # Merge with the main DataFrame\n",
    "    if df_average.empty:\n",
    "        df_average = lit_results\n",
    "    else:\n",
    "        df_average = df_average.join(lit_results, how=\"outer\")\n",
    "\n",
    "df_average = df_average.apply(pd.to_numeric).round(3)\n",
    "\n",
    "df_average = df_average[sorted(df_average.columns)]\n",
    "df_average = df_average.reset_index()\n",
    "df_average.loc[:, \"relation\"] = df_average.loc[:, \"relation\"].map(rel_map_fb15k)\n",
    "df_average = df_average[column_order]\n",
    "latex_table = df_average.to_latex(index=False, float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "relation & ComplEx & DeCaL & DistMult & Keci & Pykeen_MuRE & OMult & QMult & TransE \\\\\n",
      "\\midrule\n",
      "birthDate & 17.125 & 17.177 & 18.936 & 21.939 & 15.368 & 17.250 & 18.518 & 14.268 \\\\\n",
      "completionDate & 6.830 & 6.595 & 6.774 & 5.952 & 4.817 & 7.379 & 5.758 & 5.585 \\\\\n",
      "deathDate & 17.832 & 23.191 & 19.710 & 22.415 & 16.083 & 21.179 & 20.303 & 17.541 \\\\\n",
      "formationDate & 48.975 & 43.409 & 44.734 & 32.236 & 40.103 & 37.848 & 41.068 & 50.643 \\\\\n",
      "foundingDate & 51.188 & 65.856 & 53.620 & 51.016 & 53.584 & 54.962 & 59.488 & 55.962 \\\\\n",
      "height & 5.573 & 5.194 & 6.974 & 7.880 & 2.803 & 9.776 & 5.805 & 4.696 \\\\\n",
      "releaseDate & 8.462 & 10.308 & 11.298 & 9.869 & 7.797 & 13.182 & 12.061 & 7.695 \\\\\n",
      "latitude & 12.074 & 13.113 & 13.777 & 12.845 & 11.761 & 14.338 & 12.725 & 8.588 \\\\\n",
      "longitude & 30.602 & 58.490 & 44.876 & 53.956 & 30.707 & 41.155 & 38.674 & 32.718 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dataset = \"DB15K\"\n",
    "exp_dir = f\"Experiments/KGE_Combined/{dataset}_combined/\"\n",
    "column_order = [\"relation\", \"ComplEx\", \"DeCaL\", \"DistMult\", \"Keci\",\"Pykeen_MuRE\", \"OMult\", \"QMult\", \"TransE\"]\n",
    "df_average = pd.DataFrame() \n",
    "for sub_dir in os.listdir(exp_dir):\n",
    "    sub_path = os.path.join(exp_dir, sub_dir)\n",
    "    lit_results_path = os.path.join(sub_path,\"lit_results.json\" )\n",
    "    lit_results = pd.read_json(lit_results_path)\n",
    "    # Identify MAE and RMSE columns\n",
    "    mae_cols = [col for col in lit_results.columns if \"MAE\" in col]\n",
    "    # rmse_cols = [col for col in lit_results.columns if \"RMSE\" in col]\n",
    "\n",
    "    # Compute the mean across runs\n",
    "    lit_results[\"MAE\"] = lit_results[mae_cols].mean(axis=1)\n",
    "    # lit_results[\"RMSE\"] = lit_results[rmse_cols].mean(axis=1)\n",
    "\n",
    "    # Set relation as index\n",
    "    lit_results = lit_results.set_index(\"relation\")\n",
    "\n",
    "    lit_results = lit_results[[\"MAE\"]].rename(\n",
    "            columns={\"MAE\": f\"{sub_dir}\"}\n",
    "        )\n",
    "    # Merge with the main DataFrame\n",
    "    if df_average.empty:\n",
    "        df_average = lit_results\n",
    "    else:\n",
    "        df_average = df_average.join(lit_results, how=\"outer\")\n",
    "\n",
    "df_average = df_average.apply(pd.to_numeric).round(3)\n",
    "\n",
    "df_average = df_average[sorted(df_average.columns)]\n",
    "df_average = df_average.reset_index()\n",
    "df_average.loc[:, \"relation\"] = df_average.loc[:, \"relation\"].map(rel_map_db15k)\n",
    "df_average = df_average[column_order]\n",
    "latex_table = df_average.to_latex(index=False, float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "relation & ComplEx & DeCaL & DistMult & Keci & Pykeen_MuRE & OMult & QMult & TransE \\\\\n",
      "\\midrule\n",
      "diedOnDate & 31.610 & 38.435 & 38.988 & 39.783 & 28.930 & 36.327 & 33.353 & 28.147 \\\\\n",
      "happenedOnDate & 37.863 & 50.439 & 40.292 & 39.372 & 48.608 & 47.447 & 58.582 & 59.611 \\\\\n",
      "Latitude & 6.264 & 8.486 & 6.154 & 7.908 & 5.744 & 8.111 & 8.119 & 4.856 \\\\\n",
      "Longitude & 31.842 & 42.174 & 40.156 & 35.593 & 26.601 & 34.157 & 36.426 & 21.875 \\\\\n",
      "BornOnDate & 20.916 & 21.134 & 22.674 & 24.950 & 16.797 & 21.773 & 20.514 & 15.735 \\\\\n",
      "CreatedOnDate & 83.376 & 98.141 & 86.748 & 96.088 & 66.590 & 82.537 & 87.284 & 73.249 \\\\\n",
      "DestroyedOnDate & 31.348 & 38.790 & 35.238 & 36.076 & 30.059 & 31.893 & 32.838 & 26.995 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dataset = \"YAGO15k\"\n",
    "column_order = [\"relation\", \"ComplEx\", \"DeCaL\", \"DistMult\", \"Keci\",\"Pykeen_MuRE\", \"OMult\", \"QMult\", \"TransE\"]\n",
    "exp_dir = f\"Experiments/KGE_Combined/{dataset}_combined/\"\n",
    "df_average = pd.DataFrame() \n",
    "for sub_dir in os.listdir(exp_dir):\n",
    "    sub_path = os.path.join(exp_dir, sub_dir)\n",
    "    lit_results_path = os.path.join(sub_path,\"lit_results.json\" )\n",
    "    lit_results = pd.read_json(lit_results_path)\n",
    "    # Identify MAE and RMSE columns\n",
    "    mae_cols = [col for col in lit_results.columns if \"MAE\" in col]\n",
    "    # rmse_cols = [col for col in lit_results.columns if \"RMSE\" in col]\n",
    "\n",
    "    # Compute the mean across runs\n",
    "    lit_results[\"MAE\"] = lit_results[mae_cols].mean(axis=1)\n",
    "    # lit_results[\"RMSE\"] = lit_results[rmse_cols].mean(axis=1)\n",
    "\n",
    "    # Set relation as index\n",
    "    lit_results = lit_results.set_index(\"relation\")\n",
    "\n",
    "    lit_results = lit_results[[\"MAE\"]].rename(\n",
    "            columns={\"MAE\": f\"{sub_dir}\"}\n",
    "        )\n",
    "    # Merge with the main DataFrame\n",
    "    if df_average.empty:\n",
    "        df_average = lit_results\n",
    "    else:\n",
    "        df_average = df_average.join(lit_results, how=\"outer\")\n",
    "\n",
    "df_average = df_average.apply(pd.to_numeric).round(3)\n",
    "\n",
    "df_average = df_average[sorted(df_average.columns)]\n",
    "df_average = df_average.reset_index()\n",
    "df_average.loc[:, \"relation\"] = df_average.loc[:, \"relation\"].map(rel_map_yago15k)\n",
    "df_average = df_average[column_order]\n",
    "latex_table = df_average.to_latex(index=False, float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "relation & ComplEx & DeCaL & DistMult & Keci & Pykeen_MuRE & OMult & QMult & TransE \\\\\n",
      "\\midrule\n",
      "mutagenesis\\#act & 1.789 & 1.357 & 2.000 & 1.636 & 1.725 & 1.941 & 1.827 & 1.549 \\\\\n",
      "mutagenesis\\#charge & 0.170 & 0.181 & 0.169 & 0.179 & 0.214 & 0.201 & 0.213 & 0.172 \\\\\n",
      "mutagenesis\\#logp & 1.416 & 1.444 & 1.499 & 1.322 & 1.149 & 1.827 & 1.437 & 1.180 \\\\\n",
      "mutagenesis\\#lumo & 0.576 & 0.522 & 0.638 & 0.435 & 0.555 & 0.531 & 0.657 & 0.392 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dataset = \"mutagenesis\"\n",
    "exp_dir = f\"Experiments/KGE_Combined/{dataset}_combined/\"\n",
    "column_order = [\"relation\", \"ComplEx\", \"DeCaL\", \"DistMult\", \"Keci\",\"Pykeen_MuRE\", \"OMult\", \"QMult\", \"TransE\"]\n",
    "df_average = pd.DataFrame() \n",
    "for sub_dir in os.listdir(exp_dir):\n",
    "    sub_path = os.path.join(exp_dir, sub_dir)\n",
    "    lit_results_path = os.path.join(sub_path,\"lit_results.json\" )\n",
    "    lit_results = pd.read_json(lit_results_path)\n",
    "    # Identify MAE and RMSE columns\n",
    "    mae_cols = [col for col in lit_results.columns if \"MAE\" in col]\n",
    "    # rmse_cols = [col for col in lit_results.columns if \"RMSE\" in col]\n",
    "\n",
    "    # Compute the mean across runs\n",
    "    lit_results[\"MAE\"] = lit_results[mae_cols].mean(axis=1)\n",
    "    # lit_results[\"RMSE\"] = lit_results[rmse_cols].mean(axis=1)\n",
    "\n",
    "    # Set relation as index\n",
    "    lit_results = lit_results.set_index(\"relation\")\n",
    "\n",
    "    lit_results = lit_results[[\"MAE\"]].rename(\n",
    "            columns={\"MAE\": f\"{sub_dir}\"}\n",
    "        )\n",
    "    # Merge with the main DataFrame\n",
    "    if df_average.empty:\n",
    "        df_average = lit_results\n",
    "    else:\n",
    "        df_average = df_average.join(lit_results, how=\"outer\")\n",
    "\n",
    "df_average = df_average.apply(pd.to_numeric).round(3)\n",
    "\n",
    "df_average = df_average[sorted(df_average.columns)]\n",
    "df_average = df_average.reset_index()\n",
    "df_average = df_average[column_order]\n",
    "df_average.loc[:, \"relation\"] = df_average.loc[:, \"relation\"].map(rel_map_mutag)\n",
    "latex_table = df_average.to_latex(index=False, float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "relation & MAE_80 & RMSE_80 & MAE_60 & RMSE_60 & MAE_40 & RMSE_40 & MAE_20 & RMSE_20 \\\\\n",
      "\\midrule\n",
      "release\\_date & 2.22 & 0.60 & 5.63 & 4.60 & 3.93 & 3.07 & 13.54 & 14.56 \\\\\n",
      "loc.date\\_founded & 6.92 & -0.38 & 5.62 & 0.25 & 9.78 & 1.85 & 18.50 & 1.34 \\\\\n",
      "latitude & -1.66 & -6.78 & -2.85 & -3.69 & 4.42 & -0.33 & 11.03 & 3.23 \\\\\n",
      "longitude & -0.63 & 4.74 & -3.90 & 1.54 & 1.16 & 4.49 & 18.21 & 13.42 \\\\\n",
      "loc.area & -2.55 & 0.43 & -8.24 & 0.33 & -9.66 & 0.25 & -8.47 & 0.33 \\\\\n",
      "org.date\\_founded & 1.48 & 3.00 & 7.92 & 7.70 & 4.67 & 3.66 & 20.59 & 18.27 \\\\\n",
      "date\\_of\\_death & 4.54 & -0.84 & 6.17 & 1.56 & 4.16 & -4.22 & 25.87 & 4.98 \\\\\n",
      "date\\_of\\_birth & 5.14 & 1.42 & 4.93 & 2.49 & 2.04 & -3.98 & 10.22 & 5.50 \\\\\n",
      "height\\_meters & -0.34 & -0.11 & 1.40 & 1.78 & 2.58 & 4.10 & 4.55 & 5.72 \\\\\n",
      "weight\\_kg & -12.55 & -1.65 & -5.36 & 2.34 & -12.26 & -0.92 & -14.32 & 9.69 \\\\\n",
      "pop.\\_number & -3.69 & 0.76 & 0.87 & 3.13 & -39.99 & 2.90 & -38.35 & 1.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of dataset fractions you want to process\n",
    "fractions = [100, 80, 60, 40, 20]\n",
    "\n",
    "# Base path with a placeholder for the fraction\n",
    "base_path = \"Experiments/Ablations/FB15k-237_{}/TransE/lit_results.csv\"\n",
    "\n",
    "\n",
    "# Initialize the final DataFrame\n",
    "final_df = None\n",
    "\n",
    "for frac in fractions:\n",
    "    file_path = base_path.format(str(frac))\n",
    "    try:\n",
    "        # Read the current CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Rename MAE and RMSE columns with run-specific suffix\n",
    "        df = df.rename(columns={\n",
    "            \"MAE\": f\"MAE_{frac}\",\n",
    "            \"RMSE\": f\"RMSE_{frac}\"\n",
    "        })\n",
    "\n",
    "        # If it's the first run, start the final DataFrame\n",
    "        if final_df is None:\n",
    "            final_df = df\n",
    "        else:\n",
    "            # Merge on 'relation' to align rows\n",
    "            final_df = pd.merge(final_df, df, on=\"relation\", how=\"outer\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for fraction {frac}\")\n",
    "\n",
    "# Save or inspect the final DataFrame\n",
    "# final_df.to_csv(\"merged_metrics.csv\", index=False)\n",
    "# filtered_df = final_df.loc[:, final_df.columns.str.contains('relation|MAE', case=False)]\n",
    "\n",
    "filtered_df = final_df.copy(deep=True)\n",
    "filtered_df.loc[:, \"relation\"] = filtered_df.loc[:, \"relation\"].map(rel_map_fb15k)\n",
    "# latex_table = filtered_df.to_latex(index=False, float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "# print(latex_table)\n",
    "# Step 2: Compute relative changes (as percentages) for both MAE and RMSE columns\n",
    "for metric in ['MAE', 'RMSE']:\n",
    "    for col in [f'{metric}_80', f'{metric}_60', f'{metric}_40', f'{metric}_20']:\n",
    "        # Compute relative change for each MAE and RMSE column\n",
    "        filtered_df.loc[:, col] = (((filtered_df[col] - filtered_df[f'{metric}_100']) / filtered_df[f'{metric}_100']) * 100).round(2)\n",
    "\n",
    "# Step 3: Drop the *_100 columns if not needed\n",
    "filtered_df = filtered_df.drop(columns=[f'MAE_100', f'RMSE_100'])\n",
    "latex_table = filtered_df.to_latex(index=False, float_format=\"%.2f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "relation & MAE_80 & RMSE_80 & MAE_60 & RMSE_60 & MAE_40 & RMSE_40 & MAE_20 & RMSE_20 \\\\\n",
      "\\midrule\n",
      "diedOnDate & 0.39 & -1.44 & -0.42 & -3.37 & -0.24 & -20.20 & 9.82 & -13.45 \\\\\n",
      "happenedOnDate & -1.02 & -6.92 & -0.41 & 1.15 & 8.27 & -6.84 & 17.28 & 19.09 \\\\\n",
      "Latitude & 0.92 & -0.60 & 6.77 & 0.20 & 7.89 & 2.10 & 28.36 & 14.69 \\\\\n",
      "Longitude & 0.49 & 0.90 & 7.79 & 9.84 & 14.93 & 13.27 & 28.29 & 24.42 \\\\\n",
      "BornOnDate & -2.91 & 0.54 & 1.80 & 2.33 & -0.47 & -4.60 & 15.02 & 2.33 \\\\\n",
      "CreatedOnDate & -0.34 & -0.93 & 0.32 & -1.29 & 3.63 & 0.39 & 8.95 & -0.31 \\\\\n",
      "DestroyedOnDate & -6.67 & -4.46 & 7.16 & 0.92 & 2.15 & -8.68 & 40.74 & 14.84 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of dataset fractions you want to process\n",
    "fractions = [100, 80, 60, 40, 20]\n",
    "\n",
    "# Base path with a placeholder for the fraction\n",
    "base_path = \"Experiments/Ablations/YAGO15k_{}/TransE/lit_results.csv\"\n",
    "\n",
    "\n",
    "# Initialize the final DataFrame\n",
    "final_df = None\n",
    "\n",
    "for frac in fractions:\n",
    "    file_path = base_path.format(str(frac))\n",
    "    try:\n",
    "        # Read the current CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Rename MAE and RMSE columns with run-specific suffix\n",
    "        df = df.rename(columns={\n",
    "            \"MAE\": f\"MAE_{frac}\",\n",
    "            \"RMSE\": f\"RMSE_{frac}\"\n",
    "        })\n",
    "\n",
    "        # If it's the first run, start the final DataFrame\n",
    "        if final_df is None:\n",
    "            final_df = df\n",
    "        else:\n",
    "            # Merge on 'relation' to align rows\n",
    "            final_df = pd.merge(final_df, df, on=\"relation\", how=\"outer\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for fraction {frac}\")\n",
    "\n",
    "# Save or inspect the final DataFrame\n",
    "# final_df.to_csv(\"merged_metrics.csv\", index=False)\n",
    "# filtered_df = final_df.loc[:, final_df.columns.str.contains('relation|MAE', case=False)]\n",
    "\n",
    "filtered_df = final_df.copy(deep=True)\n",
    "filtered_df.loc[:, \"relation\"] = filtered_df.loc[:, \"relation\"].map(rel_map_yago15k)\n",
    "# latex_table = filtered_df.to_latex(index=False, float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "# print(latex_table)\n",
    "# Step 2: Compute relative changes (as percentages) for both MAE and RMSE columns\n",
    "for metric in ['MAE', 'RMSE']:\n",
    "    for col in [f'{metric}_80', f'{metric}_60', f'{metric}_40', f'{metric}_20']:\n",
    "        # Compute relative change for each MAE and RMSE column\n",
    "        filtered_df.loc[:, col] = (((filtered_df[col] - filtered_df[f'{metric}_100']) / filtered_df[f'{metric}_100']) * 100).round(2)\n",
    "\n",
    "# Step 3: Drop the *_100 columns if not needed\n",
    "filtered_df = filtered_df.drop(columns=[f'MAE_100', f'RMSE_100'])\n",
    "latex_table = filtered_df.to_latex(index=False, float_format=\"%.2f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.utils import load_model_components\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "def calculate_triple_scores(exp_path: str,exp_path_combined: str ):\n",
    "    model_components = load_model_components(exp_path)\n",
    "\n",
    "    if model_components is None:\n",
    "        print(\"Failed to load model components.\")\n",
    "        return  # Or handle as needed (e.g., raise Exception)\n",
    "\n",
    "    kge_model, configs, entity_to_idx, relation_to_idx = model_components\n",
    "\n",
    "    model_components_combined = load_model_components(exp_path_combined)\n",
    "\n",
    "    if model_components_combined is None:\n",
    "        print(\"Failed to load model components.\")\n",
    "        return  # Or handle as needed (e.g., raise Exception)\n",
    "\n",
    "    kge_model_combined, configs_combined, entity_to_idx_combined, relation_to_idx_combined= model_components_combined\n",
    "\n",
    "     \n",
    "    test_kg_dir = configs[\"dataset_dir\"] + \"/test.txt\"\n",
    "\n",
    "    # process test set and map to idx\n",
    "    test_df = pd.read_csv(\n",
    "        test_kg_dir,\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=[\"head\", \"relation\", \"tail\"],\n",
    "    ).drop_duplicates()\n",
    "    test_df[\"head_idx\"] = test_df[\"head\"].map(entity_to_idx)\n",
    "    test_df[\"rel_idx\"] = test_df[\"relation\"].map(relation_to_idx)\n",
    "    test_df[\"tail_idx\"] = test_df[\"tail\"].map(entity_to_idx)\n",
    "\n",
    "    # Create tensor from DataFrame\n",
    "    triples = torch.tensor(\n",
    "        test_df[[\"head_idx\", \"rel_idx\", \"tail_idx\"]].values, dtype=torch.long\n",
    "    )\n",
    "\n",
    "    # Forward pass with no gradient computation\n",
    "    with torch.no_grad():\n",
    "        test_df[\"scores_kge\"] = torch.sigmoid(kge_model(triples)).tolist()\n",
    "    with torch.no_grad():\n",
    "        test_df[\"scores_combined\"] = torch.sigmoid(kge_model_combined(triples)).tolist()\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sapkota/miniconda3/envs/litem/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "    model_name  mean_scores_kge  mean_scores_combined\n",
      "0       TransE            0.052                 0.048\n",
      "1     DistMult            0.157                 0.174\n",
      "2         Keci            0.184                 0.213\n",
      "3      ComplEx            0.163                 0.172\n",
      "4        OMult            0.166                 0.168\n",
      "5        QMult            0.163                 0.170\n",
      "6        DeCaL            0.282                 0.156\n",
      "7  Pykeen_MuRE            0.257                 0.254\n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "model_name & TransE & DistMult & Keci & ComplEx & OMult & QMult & DeCaL & Pykeen_MuRE \\\\\n",
      "\\midrule\n",
      "mean_scores_kge & 0.052 & 0.157 & 0.184 & 0.163 & 0.166 & 0.163 & 0.282 & 0.257 \\\\\n",
      "mean_scores_combined & 0.048 & 0.174 & 0.213 & 0.172 & 0.168 & 0.170 & 0.156 & 0.254 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp_models = [\"TransE\", \"DistMult\", \"Keci\", \"ComplEx\", \"OMult\", \"QMult\", \"DeCaL\", \"Pykeen_MuRE\"]\n",
    "\n",
    "# List to collect each model's results\n",
    "mean_scores_list = []\n",
    "\n",
    "for model_name in exp_models:\n",
    "    path_kge = f'Experiments/KGE/DB15K/{model_name}'\n",
    "    path_kge_combined = f'Experiments/KGE_Combined/DB15K_combined/{model_name}'\n",
    "\n",
    "    res_df = calculate_triple_scores(path_kge, path_kge_combined)\n",
    "    if res_df is None:\n",
    "        continue\n",
    "    # Calculate means\n",
    "    mean_kge = res_df['scores_kge'].mean()\n",
    "    mean_combined = res_df['scores_combined'].mean()\n",
    "\n",
    "    # Append result as a dictionary\n",
    "    mean_scores_list.append({\n",
    "        'model_name': model_name,\n",
    "        'mean_scores_kge': mean_kge,\n",
    "        'mean_scores_combined': mean_combined\n",
    "    })\n",
    "\n",
    "# Create final DataFrame\n",
    "mean_scores_df = pd.DataFrame(mean_scores_list)\n",
    "\n",
    "print(mean_scores_df)\n",
    "# Transpose the DataFrame to have model names as column headers\n",
    "rotated_df = mean_scores_df.set_index('model_name').T\n",
    "\n",
    "latex_table = rotated_df.to_latex( float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "Manual KGE load Successfull!!\n",
      "    model_name  mean_scores_kge  mean_scores_combined\n",
      "0       TransE            0.071                 0.069\n",
      "1     DistMult            0.182                 0.180\n",
      "2         Keci            0.174                 0.223\n",
      "3      ComplEx            0.158                 0.190\n",
      "4        OMult            0.176                 0.181\n",
      "5        QMult            0.170                 0.172\n",
      "6        DeCaL            0.463                 0.025\n",
      "7  Pykeen_MuRE            0.201                 0.220\n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "model_name & TransE & DistMult & Keci & ComplEx & OMult & QMult & DeCaL & Pykeen_MuRE \\\\\n",
      "\\midrule\n",
      "mean_scores_kge & 0.071 & 0.182 & 0.174 & 0.158 & 0.176 & 0.170 & 0.463 & 0.201 \\\\\n",
      "mean_scores_combined & 0.069 & 0.180 & 0.223 & 0.190 & 0.181 & 0.172 & 0.025 & 0.220 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp_models = [\"TransE\", \"DistMult\", \"Keci\", \"ComplEx\", \"OMult\", \"QMult\", \"DeCaL\", \"Pykeen_MuRE\"]\n",
    "\n",
    "# List to collect each model's results\n",
    "mean_scores_list = []\n",
    "\n",
    "for model_name in exp_models:\n",
    "    path_kge = f'Experiments/KGE/YAGO15k/{model_name}'\n",
    "    path_kge_combined = f'Experiments/KGE_Combined/YAGO15k_combined/{model_name}'\n",
    "\n",
    "    res_df = calculate_triple_scores(path_kge, path_kge_combined)\n",
    "    if res_df is None:\n",
    "        continue\n",
    "    # Calculate means\n",
    "    mean_kge = res_df['scores_kge'].mean()\n",
    "    mean_combined = res_df['scores_combined'].mean()\n",
    "\n",
    "    # Append result as a dictionary\n",
    "    mean_scores_list.append({\n",
    "        'model_name': model_name,\n",
    "        'mean_scores_kge': mean_kge,\n",
    "        'mean_scores_combined': mean_combined\n",
    "    })\n",
    "\n",
    "# Create final DataFrame\n",
    "mean_scores_df = pd.DataFrame(mean_scores_list)\n",
    "\n",
    "print(mean_scores_df)\n",
    "# Transpose the DataFrame to have model names as column headers\n",
    "rotated_df = mean_scores_df.set_index('model_name').T\n",
    "\n",
    "latex_table = rotated_df.to_latex( float_format=\"%.3f\")  # Format floats to 3 decimal places\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "litem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
